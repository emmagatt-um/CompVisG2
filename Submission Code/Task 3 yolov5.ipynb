{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All classes: ['basil', 'beef', 'dw', 'ham', 'hamburger', 'olive', 'olives', 'onion', 'pepper', 'pepperoni', 'pesto', 'pineapple', 'pizza', 'soup']\n",
      "Warning: Image dimensions are zero in c:\\Users\\elisa\\SynologyDrive\\University\\Third Year\\Computer Vision\\Annotations 2\\HJC4OP1AU67B.xml. Skipping.\n",
      "Conversion to YOLO format completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# The current directory where the notebook is located\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "#annotation directories\n",
    "annotation_dirs = ['Annotations 1', 'Annotations 2', 'Annotations 3']\n",
    "\n",
    "# Extract classes from XML files\n",
    "def extract_classes_from_xml(directory):\n",
    "    classes = set()\n",
    "    # Search for all XML files in the directory\n",
    "    for xml_file in glob.glob(os.path.join(directory, '*.xml')):\n",
    "        tree = ET.parse(xml_file)\n",
    "        for obj in tree.getroot().iter('object'):\n",
    "            # Add the class name to the set\n",
    "            classes.add(obj.find('name').text)\n",
    "    return classes\n",
    "\n",
    "\n",
    "all_classes = set()\n",
    "\n",
    "# Iterate over each annotation directory and update the set of classes\n",
    "for annotation_dir in annotation_dirs:\n",
    "    dir_path = os.path.join(current_directory, annotation_dir)\n",
    "    all_classes.update(extract_classes_from_xml(dir_path))\n",
    "\n",
    "# Convert the set to a list and sort it to maintain a consistent order\n",
    "all_classes = sorted(list(all_classes))\n",
    "print(f\"All classes: {all_classes}\")\n",
    "\n",
    "# Convert XML to YOLO format\n",
    "def convert_to_yolo_format(xml_file, output_file, class_list):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    image_width = int(size.find('width').text)\n",
    "    image_height = int(size.find('height').text)\n",
    "\n",
    "    if image_width == 0 or image_height == 0:\n",
    "        # Handle the case where width or height is zero\n",
    "        print(f\"Warning: Image dimensions are zero in {xml_file}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    with open(output_file, 'w') as out_file:\n",
    "        for obj in root.iter('object'):\n",
    "            class_name = obj.find('name').text\n",
    "            class_id = class_list.index(class_name)\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = float(bndbox.find('xmin').text)\n",
    "            xmax = float(bndbox.find('xmax').text)\n",
    "            ymin = float(bndbox.find('ymin').text)\n",
    "            ymax = float(bndbox.find('ymax').text)\n",
    "\n",
    "            x_center = (xmin + xmax) / 2.0\n",
    "            y_center = (ymin + ymax) / 2.0\n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "\n",
    "            # Normalize coordinates to values between 0 and 1\n",
    "            x_center /= image_width\n",
    "            y_center /= image_height\n",
    "            width /= image_width\n",
    "            height /= image_height\n",
    "\n",
    "            # Write to the output file in YOLO format\n",
    "            out_file.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "# Output directory for YOLO format annotations\n",
    "output_dir = os.path.join(current_directory, 'YOLO_annotations')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process all XML files and convert them to YOLO format text files\n",
    "for annotation_dir in annotation_dirs:\n",
    "    dir_path = os.path.join(current_directory, annotation_dir)\n",
    "\n",
    "    for xml_file in glob.glob(os.path.join(dir_path, '*.xml')):\n",
    "        file_name = os.path.splitext(os.path.basename(xml_file))[0]\n",
    "        output_file = os.path.join(output_dir, file_name + '.txt')\n",
    "        convert_to_yolo_format(xml_file, output_file, all_classes)\n",
    "\n",
    "print(\"Conversion to YOLO format completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO annotations split into training, validation, and testing sets.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The current directory where the YOLO annotations are located\n",
    "current_directory = os.getcwd()\n",
    "yolo_annotations_dir = os.path.join(current_directory, 'YOLO_annotations')\n",
    "\n",
    "# List all YOLO annotation files\n",
    "annotation_files = glob.glob(os.path.join(yolo_annotations_dir, '*.txt'))\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_ratio = 0.7  # 70% for training\n",
    "val_ratio = 0.15   # 15% for validation\n",
    "test_ratio = 0.15  # 15% for testing\n",
    "\n",
    "train_files, test_files = train_test_split(annotation_files, test_size=val_ratio + test_ratio, random_state=42)\n",
    "val_files, test_files = train_test_split(test_files, test_size=test_ratio / (val_ratio + test_ratio), random_state=42)\n",
    "\n",
    "# Create directories for the sets\n",
    "train_dir = os.path.join(yolo_annotations_dir, 'train')\n",
    "val_dir = os.path.join(yolo_annotations_dir, 'val')\n",
    "test_dir = os.path.join(yolo_annotations_dir, 'test')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Move annotation files to their respective sets\n",
    "for annotation_file in train_files:\n",
    "    file_name = os.path.basename(annotation_file)\n",
    "    os.rename(annotation_file, os.path.join(train_dir, file_name))\n",
    "\n",
    "for annotation_file in val_files:\n",
    "    file_name = os.path.basename(annotation_file)\n",
    "    os.rename(annotation_file, os.path.join(val_dir, file_name))\n",
    "\n",
    "for annotation_file in test_files:\n",
    "    file_name = os.path.basename(annotation_file)\n",
    "    os.rename(annotation_file, os.path.join(test_dir, file_name))\n",
    "\n",
    "print(\"YOLO annotations split into training, validation, and testing sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image and annotation processing and splitting completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Input directory for original images and base output directory\n",
    "input_directory = 'Images'\n",
    "output_base_directory = 'Processed_Images'\n",
    "\n",
    "# Directories for the existing YOLO annotation sets\n",
    "annotation_dirs = {\n",
    "    'train': 'YOLO_annotations/train',\n",
    "    'val': 'YOLO_annotations/val',\n",
    "    'test': 'YOLO_annotations/test'\n",
    "}\n",
    "\n",
    "# `Output directories for images and labels\n",
    "output_image_dirs = {k: os.path.join(output_base_directory, 'images', k) for k in annotation_dirs.keys()}\n",
    "output_label_dirs = {k: os.path.join(output_base_directory, 'labels', k) for k in annotation_dirs.keys()}\n",
    "\n",
    "# Ensure all output directories exist\n",
    "for dir in list(output_image_dirs.values()) + list(output_label_dirs.values()):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# Target size for resizing\n",
    "target_size = (640,640)\n",
    "\n",
    "# Resize and pad images to maintain aspect ratio\n",
    "def resize_and_pad(image, target_size):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized_image = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    pad_top = (target_size[0] - new_h) // 2\n",
    "    pad_left = (target_size[1] - new_w) // 2\n",
    "\n",
    "    padded_image[pad_top:pad_top + new_h, pad_left:pad_left + new_w] = resized_image\n",
    "    return padded_image\n",
    "\n",
    "# Process and save images\n",
    "def process_and_save_images(file_list, output_image_dir, ann_dir):\n",
    "    for filename in file_list:\n",
    "        input_path = os.path.join(input_directory, filename)\n",
    "        output_path = os.path.join(output_image_dir, filename)\n",
    "\n",
    "        image = cv2.imread(input_path)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Unable to load image at {input_path}. Deleting corresponding annotation.\")\n",
    "            annotation_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "            ann_file_path = os.path.join(ann_dir, annotation_filename)\n",
    "            if os.path.exists(ann_file_path):\n",
    "                os.remove(ann_file_path)\n",
    "            continue\n",
    "\n",
    "        image = resize_and_pad(image, target_size)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        cv2.imwrite(output_path, (image * 255).astype(np.uint8))\n",
    "\n",
    "# Process and copy images and annotations\n",
    "for set_name, ann_dir in annotation_dirs.items():\n",
    "    # List all annotation files in the directory\n",
    "    ann_files = glob.glob(os.path.join(ann_dir, '*.txt'))\n",
    "    \n",
    "    # List corresponding image filenames\n",
    "    img_files = [os.path.splitext(os.path.basename(f))[0] + '.jpg' for f in ann_files]  \n",
    "\n",
    "    # Process and save the images to the corresponding set directory\n",
    "    process_and_save_images(img_files, output_image_dirs[set_name], ann_dir)\n",
    "\n",
    "    # Copy the remaining annotation files to the corresponding set directory\n",
    "    for ann_file in glob.glob(os.path.join(ann_dir, '*.txt')):\n",
    "        dst_annotation_path = os.path.join(output_label_dirs[set_name], os.path.basename(ann_file))\n",
    "        shutil.copy(ann_file, dst_annotation_path)\n",
    "\n",
    "print(\"Image and annotation processing and splitting completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images in train have corresponding label files.\n",
      "All images in val have corresponding label files.\n",
      "All images in test have corresponding label files.\n"
     ]
    }
   ],
   "source": [
    "# Base directories for images and labels\n",
    "base_image_directory = 'Processed_Images\\images'  # Adjust with your path\n",
    "base_label_directory = 'Processed_Images\\labels'  # Adjust with your path\n",
    "\n",
    "# Subdirectories\n",
    "subdirs = ['train', 'val', 'test']\n",
    "\n",
    "# Check matching files\n",
    "def check_matching_files(image_dir, label_dir):\n",
    "    image_files = {os.path.splitext(file)[0] for file in os.listdir(image_dir) if file.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "    label_files = {os.path.splitext(file)[0] for file in os.listdir(label_dir) if file.endswith('.txt')}\n",
    "\n",
    "    missing_labels = image_files - label_files\n",
    "    missing_images = label_files - image_files\n",
    "\n",
    "    if missing_labels:\n",
    "        print(f\"Missing label files in {os.path.basename(label_dir)}: {missing_labels}\")\n",
    "\n",
    "    if missing_images:\n",
    "        print(f\"Missing image files in {os.path.basename(image_dir)}: {missing_images}\")\n",
    "\n",
    "    if not missing_labels and not missing_images:\n",
    "        print(f\"All images in {os.path.basename(image_dir)} have corresponding label files.\")\n",
    "\n",
    "# Check each subdirectory\n",
    "for subdir in subdirs:\n",
    "    image_dir = os.path.join(base_image_directory, subdir)\n",
    "    label_dir = os.path.join(base_label_directory, subdir)\n",
    "    check_matching_files(image_dir, label_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels in 'train' have corresponding image files.\n",
      "All labels in 'val' have corresponding image files.\n",
      "All labels in 'test' have corresponding image files.\n"
     ]
    }
   ],
   "source": [
    "# Base directories for images and labels\n",
    "base_image_directory = 'Processed_Images/images'  \n",
    "base_label_directory = 'Processed_Images/labels'  \n",
    "\n",
    "# Subdirectories\n",
    "subdirs = ['train', 'val', 'test']\n",
    "\n",
    "# Check if each label has a corresponding image file\n",
    "def check_labels_have_images(image_dir, label_dir):\n",
    "    image_files = {os.path.splitext(file)[0] for file in os.listdir(image_dir) if file.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "    label_files = {os.path.splitext(file)[0] for file in os.listdir(label_dir) if file.endswith('.txt')}\n",
    "\n",
    "    missing_images_for_labels = label_files - image_files\n",
    "\n",
    "    if missing_images_for_labels:\n",
    "        print(f\"In '{os.path.basename(label_dir)}', the following labels have no corresponding images: {missing_images_for_labels}\")\n",
    "    else:\n",
    "        print(f\"All labels in '{os.path.basename(label_dir)}' have corresponding image files.\")\n",
    "\n",
    "# Check each subdirectory\n",
    "for subdir in subdirs:\n",
    "    image_dir = os.path.join(base_image_directory, subdir)\n",
    "    label_dir = os.path.join(base_label_directory, subdir)\n",
    "    check_labels_have_images(image_dir, label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training yolov5 model in terminal:\n",
    "\n",
    "python train.py --img 640 --batch 16 --epochs 50 --data data.yaml --cfg yolov5s.yaml --weights yolov5s.pt --name yolov5_custom\n",
    "\n",
    "Testing:\n",
    "\n",
    "python val.py --weights runs/train/yolov5_custom2/weights/best.pt --data data.yaml --img 640 --task test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
